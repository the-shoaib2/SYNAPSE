---
title: "Cerebras"
---

Cerebras Inference uses specialized silicon to provides fast inference.

1. Create an account in the portal [here](https://cloud.cerebras.ai/).
2. Create and copy the API key for use in Synapse.
3. Update your Synapse config file:

<Tabs>
  <Tab title="YAML">
  ```yaml title="config.yaml"
  models:
    - name: Cerebras Llama 3.1 70B
      provider: cerebras
      model: llama3.1-70b
      apiKey:  <YOUR_CEREBRAS_API_KEY>
  ```
  </Tab>
  <Tab title="JSON">
  ```json title="config.json"
  {
    "models": [
      {
        "title": "Cerebras Llama 3.1 70B",
        "provider": "cerebras",
        "model": "llama3.1-70b",
        "apiKey": "<YOUR_CEREBRAS_API_KEY>"
      }
    ]
  }
  ```
  </Tab>
</Tabs>
